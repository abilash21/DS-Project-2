{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT - 2 IMAGE CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you'll classify images from the CIFAR-10 dataset\n",
    "(https://www.cs.toronto.edu/~kriz/cifar.html). The dataset consists of airplanes, dogs, cats, and other\n",
    "objects. You'll preprocess the images, then train a convolutional neural network on all the samples.\n",
    "The images need to be normalized and the labels need to be one-hot encoded. You'll get to apply\n",
    "what you learned and build a convolutional, max pooling, dropout, and fully connected layers. At the\n",
    "end, you'll get to see your neural network's predictions on the sample images.\n",
    "Get the Data\n",
    "Run the following cell to download the CIFAR-10 dataset for python\n",
    "(https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz).\n",
    "Data\n",
    "CIFAR-10 is an established computer-vision dataset used for object recognition. It is a subset of the\n",
    "80 million tiny images dataset and consists of 60,000 32x32 color images containing one of 10\n",
    "object classes, with 6000 images per class. It was collected by Alex Krizhevsky, Vinod Nair, and\n",
    "Geoffrey Hinton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing all required references\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "import pickle\n",
    "import numpy as np\n",
    "from six.moves import urllib\n",
    "from time import time\n",
    "from time import sleep\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"./data/cifar-10-batches-py/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to convert classes into One Hot Labels\n",
    "def dense_to_one_hot(labels_dense, num_classes=10):\n",
    "    \n",
    "    num_labels = labels_dense.shape[0] #Get total Number of Records\n",
    "    index_offset = np.arange(num_labels) * num_classes # Get an numpy array  into Index Offset from 0 to total number of records\n",
    "    labels_one_hot = np.zeros((num_labels, num_classes)) # Create an Numpy array of Zeros with shape noOfRecords and noOfClass  \n",
    "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1 #Use Flat function to form One Hot Label Encoder\n",
    "\n",
    "    return labels_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function  to get the Raw Data for Training and Validation\n",
    "def get_data_set(name=\"train\"):\n",
    "    \n",
    "#     Create Empty List which has to be returned\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    #Get all filenames from the Data folder\n",
    "    filenames = [os.path.join(data_dir, 'data_batch_%d' % i) for i in range(1, 6)]\n",
    "    #Get Data for training\n",
    "    if name== \"train\":\n",
    "        #Loop through All filenames\n",
    "        for filename in filenames:\n",
    "            file = open(filename,'rb') #Open the File in read only and binary format\n",
    "            dicts =pickle.load(file, encoding='latin1') #Load data into dicts by encosing using 'latin1'\n",
    "            file.close() #Close the file\n",
    "            x = dicts[\"data\"] #Read the Data\n",
    "            y = dicts[\"labels\"] #Read the labels\n",
    "            #Convert Data into Numpy Array by dividing all values by 255. 255 because the RGB format is 255 X 255 X 255\n",
    "            x = np.array(x, dtype=float) / 255.0  \n",
    "            x = x.reshape([-1, 3, 32, 32]) # Reshape to 3,32,32 array. Input data is 32x32x3\n",
    "            x = x.transpose([0, 2, 3, 1]) # Transpose the data\n",
    "            x = x.reshape(-1, 32*32*3) # Reshape back to size of input\n",
    "    \n",
    "            #Save the Data to the X,Y\n",
    "            if len(X) == 0:\n",
    "                X = x\n",
    "                Y = y\n",
    "            else:\n",
    "                X = np.concatenate((X, x), axis=0)\n",
    "                Y = np.concatenate((Y, y), axis=0)\n",
    "                \n",
    "    #Get Data for Validation/Test. Similar process to get data from train data.\n",
    "    elif name is \"test\":\n",
    "        \n",
    "        f = open(data_dir+'/test_batch', 'rb')\n",
    "        dicts = pickle.load(f, encoding='latin1')\n",
    "        f.close()\n",
    "        X = dicts[\"data\"]\n",
    "        Y = np.array(dicts[\"labels\"])\n",
    "        X = np.array(X, dtype=float) / 255.0\n",
    "        X = X.reshape([-1, 3, 32, 32])\n",
    "        X = X.transpose([0, 2, 3, 1])\n",
    "        X = X.reshape(-1, 32*32*3)\n",
    "                      \n",
    "    return X, dense_to_one_hot(Y) #Return X value and One Hot Encoded Y value\n",
    "     \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data Completed\n"
     ]
    }
   ],
   "source": [
    "# Read Data in to Train and Test Variables\n",
    "train_x, train_y = get_data_set(\"train\")\n",
    "test_x, test_y = get_data_set(\"test\")\n",
    "print(\"Reading Data Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph() # Reset the Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model():\n",
    "    \"\"\"\n",
    "    Create the Model for the CNN Image recongnization. AlexNet kind of architecture is followed.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Get the Image Size, Channels and Num of Classes\n",
    "    _IMAGE_SIZE = 32\n",
    "    _IMAGE_CHANNELS = 3\n",
    "    _NUM_CLASSES = 10\n",
    "\n",
    "    \n",
    "    # Create Placeholder for the variables\n",
    "    with tf.name_scope('main_params'):\n",
    "        x = tf.placeholder(tf.float32, shape=[None, _IMAGE_SIZE * _IMAGE_SIZE * _IMAGE_CHANNELS], name='Input')\n",
    "        y = tf.placeholder(tf.float32, shape=[None, _NUM_CLASSES], name='Output')\n",
    "        x_image = tf.reshape(x, [-1, _IMAGE_SIZE, _IMAGE_SIZE, _IMAGE_CHANNELS], name='images') #Reshape the inputs\n",
    "\n",
    "#         global_step = tf.Variable(initial_value=0, trainable=False, name='global_step')\n",
    "        learning_rate = tf.placeholder(tf.float32, shape=[], name='learning_rate')\n",
    "\n",
    "    # Create the First Convolutional Layer\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        conv = tf.layers.conv2d(\n",
    "            inputs=x_image,\n",
    "            filters=32,\n",
    "            kernel_size=[3, 3],\n",
    "            padding='SAME',\n",
    "            activation=tf.nn.relu # RelU activation used\n",
    "        )\n",
    "        conv = tf.layers.conv2d(\n",
    "            inputs=conv,\n",
    "            filters=64,\n",
    "            kernel_size=[3, 3],\n",
    "            padding='SAME',\n",
    "            activation=tf.nn.relu # RelU activation used\n",
    "        )\n",
    "        #Create an pooling Layer\n",
    "        pool = tf.layers.max_pooling2d(conv, pool_size=[2, 2], strides=2, padding='SAME')\n",
    "        #Create a dropout layer - to reduce Overfitting\n",
    "        drop = tf.layers.dropout(pool, rate=0.25, name=scope.name)\n",
    "\n",
    "    # Create the second Convolutiona Layer\n",
    "    with tf.variable_scope('conv2') as scope:\n",
    "        conv = tf.layers.conv2d(\n",
    "            inputs=drop,\n",
    "            filters=128,\n",
    "            kernel_size=[3, 3],\n",
    "            padding='SAME',\n",
    "            activation=tf.nn.relu # RelU activation used\n",
    "        )\n",
    "        # Pooling layer with SAME Padding\n",
    "        pool = tf.layers.max_pooling2d(conv, pool_size=[2, 2], strides=2, padding='SAME')\n",
    "        conv = tf.layers.conv2d(\n",
    "            inputs=pool,\n",
    "            filters=128,\n",
    "            kernel_size=[2, 2],\n",
    "            padding='SAME',\n",
    "            activation=tf.nn.relu # RelU activation used\n",
    "        )\n",
    "        # Pooling Layer with 2x2 stride with SAME padding\n",
    "        pool = tf.layers.max_pooling2d(conv, pool_size=[2, 2], strides=2, padding='SAME')\n",
    "        drop = tf.layers.dropout(pool, rate=0.25, name=scope.name)\n",
    "\n",
    "    # Create a Fully Connecgted Dense Layer\n",
    "    with tf.variable_scope('fully_connected') as scope:\n",
    "        flat = tf.reshape(drop, [-1, 4 * 4 * 128])\n",
    "\n",
    "        fc = tf.layers.dense(inputs=flat, units=1500, activation=tf.nn.relu)\n",
    "        drop = tf.layers.dropout(fc, rate=0.5)\n",
    "        \n",
    "        #Create Softmax layer for the output Layer\n",
    "        softmax = tf.layers.dense(inputs=drop, units=_NUM_CLASSES, activation=tf.nn.softmax, name=scope.name)\n",
    "\n",
    "    # Predict the maximum of the Softmax as one of the 10 classes\n",
    "    y_pred_cls = tf.argmax(softmax, axis=1)\n",
    "\n",
    "    return x, y, softmax, y_pred_cls, learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the Learning Rate for the Training based on the Epoch counts\n",
    "def lr(epoch):\n",
    "    learning_rate = 1e-3\n",
    "    if epoch > 80:\n",
    "        learning_rate *= 0.5e-3\n",
    "    elif epoch > 60:\n",
    "        learning_rate *= 1e-3\n",
    "    elif epoch > 40:\n",
    "        learning_rate *= 1e-2\n",
    "    elif epoch > 20:\n",
    "        learning_rate *= 1e-1\n",
    "    return learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hyper Parameters\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 64\n",
    "SAVER_PATH = \"./saved_model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Cell to create  Model, Create Loss, Optimize to update weights, and Identify the Prediction Accuracy\n",
    "X,Y,logits, y_pred_class,learning_rate = model()\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y)) # Get the Loss\n",
    "# minimize loss using Adam Optimizer\n",
    "optimizer  = tf.train.AdamOptimizer(learning_rate=learning_rate,\n",
    "                                   beta1=0.9,\n",
    "                                   beta2=0.999,\n",
    "                                   epsilon=1e-08).minimize(cost)\n",
    "\n",
    "#Initialize the tensor flow variables\n",
    "init=tf.global_variables_initializer()\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create the Session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Completed in  12.991959758599599 minutes\n",
      "\n",
      "Validation Result for Epoch 1 - accuracy: 54.53% (5453/10000)\n",
      "\n",
      "Epoch 2 Completed in  13.021061432361602 minutes\n",
      "\n",
      "Validation Result for Epoch 2 - accuracy: 62.09% (6209/10000)\n",
      "\n",
      "Epoch 3 Completed in  12.989992984135945 minutes\n",
      "\n",
      "Validation Result for Epoch 3 - accuracy: 63.17% (6317/10000)\n",
      "\n",
      "Epoch 4 Completed in  12.961124670505523 minutes\n",
      "\n",
      "Validation Result for Epoch 4 - accuracy: 65.29% (6529/10000)\n",
      "\n",
      "Epoch 5 Completed in  12.97022518714269 minutes\n",
      "\n",
      "Validation Result for Epoch 5 - accuracy: 65.35% (6535/10000)\n",
      "\n",
      "Epoch 6 Completed in  13.752553264300028 minutes\n",
      "\n",
      "Validation Result for Epoch 6 - accuracy: 68.06% (6806/10000)\n",
      "\n",
      "Epoch 7 Completed in  14.194361873467763 minutes\n",
      "\n",
      "Validation Result for Epoch 7 - accuracy: 68.24% (6824/10000)\n",
      "\n",
      "Epoch 8 Completed in  13.91991283496221 minutes\n",
      "\n",
      "Validation Result for Epoch 8 - accuracy: 70.77% (7077/10000)\n",
      "\n",
      "Epoch 9 Completed in  13.909512241681417 minutes\n",
      "\n",
      "Validation Result for Epoch 9 - accuracy: 69.73% (6973/10000)\n",
      "\n",
      "Epoch 10 Completed in  13.958581721782684 minutes\n",
      "\n",
      "Validation Result for Epoch 10 - accuracy: 69.49% (6949/10000)\n",
      "\n",
      "Epoch 11 Completed in  13.973515903949737 minutes\n",
      "\n",
      "Validation Result for Epoch 11 - accuracy: 68.77% (6877/10000)\n",
      "\n",
      "Epoch 12 Completed in  14.097956355412801 minutes\n",
      "\n",
      "Validation Result for Epoch 12 - accuracy: 70.52% (7052/10000)\n",
      "\n",
      "Epoch 13 Completed in  13.999684071540832 minutes\n",
      "\n",
      "Validation Result for Epoch 13 - accuracy: 71.78% (7178/10000)\n",
      "\n",
      "Epoch 14 Completed in  13.869359950224558 minutes\n",
      "\n",
      "Validation Result for Epoch 14 - accuracy: 70.51% (7051/10000)\n",
      "\n",
      "Epoch 15 Completed in  13.964448722203572 minutes\n",
      "\n",
      "Validation Result for Epoch 15 - accuracy: 69.73% (6973/10000)\n",
      "\n",
      "Epoch 16 Completed in  14.073988318443298 minutes\n",
      "\n",
      "Validation Result for Epoch 16 - accuracy: 68.21% (6821/10000)\n",
      "\n",
      "Epoch 17 Completed in  14.098273042837778 minutes\n",
      "\n",
      "Validation Result for Epoch 17 - accuracy: 70.25% (7025/10000)\n",
      "\n",
      "Epoch 18 Completed in  14.099906468391419 minutes\n",
      "\n",
      "Validation Result for Epoch 18 - accuracy: 69.16% (6916/10000)\n",
      "\n",
      "Epoch 19 Completed in  14.09383945465088 minutes\n",
      "\n",
      "Validation Result for Epoch 19 - accuracy: 66.15% (6615/10000)\n",
      "\n",
      "Epoch 20 Completed in  14.174977429707845 minutes\n",
      "\n",
      "Validation Result for Epoch 20 - accuracy: 69.90% (6990/10000)\n",
      "\n",
      "Epoch 21 Completed in  14.18864487806956 minutes\n",
      "\n",
      "Validation Result for Epoch 21 - accuracy: 69.02% (6902/10000)\n",
      "\n",
      "Epoch 22 Completed in  14.03058584133784 minutes\n",
      "\n",
      "Validation Result for Epoch 22 - accuracy: 73.95% (7395/10000)\n",
      "\n",
      "Epoch 23 Completed in  14.163360098997751 minutes\n",
      "\n",
      "Validation Result for Epoch 23 - accuracy: 74.31% (7431/10000)\n",
      "\n",
      "Epoch 24 Completed in  14.208629349867502 minutes\n",
      "\n",
      "Validation Result for Epoch 24 - accuracy: 74.48% (7448/10000)\n",
      "\n",
      "Epoch 25 Completed in  14.359187964598338 minutes\n",
      "\n",
      "Validation Result for Epoch 25 - accuracy: 74.87% (7487/10000)\n",
      "\n",
      "Epoch 26 Completed in  14.169543782869974 minutes\n",
      "\n",
      "Validation Result for Epoch 26 - accuracy: 74.97% (7497/10000)\n",
      "\n",
      "Epoch 27 Completed in  14.155159628391266 minutes\n",
      "\n",
      "Validation Result for Epoch 27 - accuracy: 75.14% (7514/10000)\n",
      "\n",
      "Epoch 28 Completed in  14.16731032927831 minutes\n",
      "\n",
      "Validation Result for Epoch 28 - accuracy: 75.67% (7567/10000)\n",
      "\n",
      "Epoch 29 Completed in  14.339436837037404 minutes\n",
      "\n",
      "Validation Result for Epoch 29 - accuracy: 75.74% (7574/10000)\n",
      "\n",
      "Epoch 30 Completed in  14.457076899210612 minutes\n",
      "\n",
      "Validation Result for Epoch 30 - accuracy: 75.63% (7563/10000)\n",
      "\n",
      "Epoch 31 Completed in  14.379889150460562 minutes\n",
      "\n",
      "Validation Result for Epoch 31 - accuracy: 75.83% (7583/10000)\n",
      "\n",
      "Epoch 32 Completed in  14.077438513437906 minutes\n",
      "\n",
      "Validation Result for Epoch 32 - accuracy: 75.81% (7581/10000)\n",
      "\n",
      "Epoch 33 Completed in  14.121907722949981 minutes\n",
      "\n",
      "Validation Result for Epoch 33 - accuracy: 76.13% (7613/10000)\n",
      "\n",
      "Epoch 34 Completed in  14.0970729748408 minutes\n",
      "\n",
      "Validation Result for Epoch 34 - accuracy: 76.04% (7604/10000)\n",
      "\n",
      "Epoch 35 Completed in  14.069904752572377 minutes\n",
      "\n",
      "Validation Result for Epoch 35 - accuracy: 75.95% (7595/10000)\n",
      "\n",
      "Epoch 36 Completed in  14.240981205304463 minutes\n",
      "\n",
      "Validation Result for Epoch 36 - accuracy: 76.05% (7605/10000)\n",
      "\n",
      "Epoch 37 Completed in  14.165310208002726 minutes\n",
      "\n",
      "Validation Result for Epoch 37 - accuracy: 75.84% (7584/10000)\n",
      "\n",
      "Epoch 38 Completed in  14.129791510105132 minutes\n",
      "\n",
      "Validation Result for Epoch 38 - accuracy: 75.89% (7589/10000)\n",
      "\n",
      "Epoch 39 Completed in  14.099389771620432 minutes\n",
      "\n",
      "Validation Result for Epoch 39 - accuracy: 76.39% (7639/10000)\n",
      "\n",
      "Epoch 40 Completed in  14.040103050072988 minutes\n",
      "\n",
      "Validation Result for Epoch 40 - accuracy: 76.32% (7632/10000)\n",
      "\n",
      "Epoch 41 Completed in  25.197891239325205 minutes\n",
      "\n",
      "Validation Result for Epoch 41 - accuracy: 76.32% (7632/10000)\n",
      "\n",
      "Epoch 42 Completed in  40.94329181909561 minutes\n",
      "\n",
      "Validation Result for Epoch 42 - accuracy: 76.40% (7640/10000)\n",
      "\n",
      "Epoch 43 Completed in  24.929992580413817 minutes\n",
      "\n",
      "Validation Result for Epoch 43 - accuracy: 76.30% (7630/10000)\n",
      "\n",
      "Epoch 44 Completed in  12.916338773568471 minutes\n",
      "\n",
      "Validation Result for Epoch 44 - accuracy: 76.25% (7625/10000)\n",
      "\n",
      "Epoch 45 Completed in  12.904004736741383 minutes\n",
      "\n",
      "Validation Result for Epoch 45 - accuracy: 76.28% (7628/10000)\n",
      "\n",
      "Epoch 46 Completed in  12.948907299836476 minutes\n",
      "\n",
      "Validation Result for Epoch 46 - accuracy: 76.31% (7631/10000)\n",
      "\n",
      "Epoch 47 Completed in  19.234033461411794 minutes\n",
      "\n",
      "Validation Result for Epoch 47 - accuracy: 76.31% (7631/10000)\n",
      "\n",
      "Epoch 48 Completed in  42.68620817263921 minutes\n",
      "\n",
      "Validation Result for Epoch 48 - accuracy: 76.33% (7633/10000)\n",
      "\n",
      "Epoch 49 Completed in  24.539370234807333 minutes\n",
      "\n",
      "Validation Result for Epoch 49 - accuracy: 76.34% (7634/10000)\n",
      "\n",
      "Epoch 50 Completed in  12.97549215555191 minutes\n",
      "\n",
      "Validation Result for Epoch 50 - accuracy: 76.23% (7623/10000)\n",
      "\n",
      "Epoch 51 Completed in  12.99184309244156 minutes\n",
      "\n",
      "Validation Result for Epoch 51 - accuracy: 76.24% (7624/10000)\n",
      "\n",
      "Epoch 52 Completed in  12.914588677883149 minutes\n",
      "\n",
      "Validation Result for Epoch 52 - accuracy: 76.29% (7629/10000)\n",
      "\n",
      "Epoch 53 Completed in  12.91558872461319 minutes\n",
      "\n",
      "Validation Result for Epoch 53 - accuracy: 76.32% (7632/10000)\n",
      "\n",
      "Epoch 54 Completed in  12.946573837598164 minutes\n",
      "\n",
      "Validation Result for Epoch 54 - accuracy: 76.43% (7643/10000)\n",
      "\n",
      "Epoch 55 Completed in  12.915288710594178 minutes\n",
      "\n",
      "Validation Result for Epoch 55 - accuracy: 76.34% (7634/10000)\n",
      "\n",
      "Epoch 56 Completed in  12.92685604095459 minutes\n",
      "\n",
      "Validation Result for Epoch 56 - accuracy: 76.33% (7633/10000)\n",
      "\n",
      "Epoch 57 Completed in  12.908771673838297 minutes\n",
      "\n",
      "Validation Result for Epoch 57 - accuracy: 76.35% (7635/10000)\n",
      "\n",
      "Epoch 58 Completed in  12.907471597194672 minutes\n",
      "\n",
      "Validation Result for Epoch 58 - accuracy: 76.38% (7638/10000)\n",
      "\n",
      "Epoch 59 Completed in  12.911755176385244 minutes\n",
      "\n",
      "Validation Result for Epoch 59 - accuracy: 76.34% (7634/10000)\n",
      "\n",
      "Epoch 60 Completed in  12.933039732774098 minutes\n",
      "\n",
      "Validation Result for Epoch 60 - accuracy: 76.36% (7636/10000)\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE MODEL WITH A PREDEFINED EPOCHS\n",
    "\n",
    "#Identify the batch count using the Batch Size\n",
    "batches = int(math.ceil(len(train_x)/BATCH_SIZE))\n",
    "\n",
    "for epoch in range(EPOCHS): # Loop through for the EPOCHS\n",
    "    \n",
    "    start_time = time()\n",
    "    \n",
    "    for batch in range(batches): # Loop through the Batches\n",
    "        batch_x = train_x[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE] # Get batch X Data\n",
    "        batch_y = train_y[batch*BATCH_SIZE:(batch+1)*BATCH_SIZE] # Get batch Y Data\n",
    "        \n",
    "        batch_loss, _, batch_acc = sess.run([cost, optimizer,  accuracy],\n",
    "            feed_dict={X: batch_x, Y: batch_y, learning_rate: lr(epoch)}) # Get the batch Loss and accuracy (Basically Training)\n",
    "        \n",
    "    duration = time()-start_time\n",
    "\n",
    "    #on Each EPOCH Completion display the message\n",
    "    print(\"\\nEpoch {} Completed in  {} minutes\".format((epoch+1),duration/60))\n",
    "\n",
    "    # Do the validation accuracy with Test Data\n",
    "    \n",
    "    i=0\n",
    "    predicted_class=[]\n",
    "    \n",
    "    # Loop and validate all test Data\n",
    "    while (i < len(test_x)):\n",
    "        \n",
    "        j = min(i + BATCH_SIZE, len(test_x))\n",
    "        batch_test_x = test_x[i:j, :]\n",
    "        batch_test_y = test_y[i:j, :]\n",
    "        \n",
    "        # Get the Model Prediction\n",
    "        predicted_class[i:j] = sess.run(y_pred_class,feed_dict={X: batch_test_x, Y: batch_test_y, learning_rate: lr(epoch)})\n",
    "        i =j\n",
    "    \n",
    "    # Identify the accuracy\n",
    "    correct= (np.argmax(test_y, axis=1) == predicted_class)\n",
    "    valid_acc = correct.mean()*100\n",
    "    correct_validated = correct.sum()\n",
    "    \n",
    "    #Print Validation accuracy after each EPOCHS\n",
    "    mes = \"\\nValidation Result for Epoch {} - accuracy: {:.2f}% ({}/{})\"\n",
    "    print(mes.format((epoch+1), valid_acc, correct_validated, len(test_x)))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# With System Limitation, the Model took more than 25 hrs to complete\n",
    "NO OF EPOCHS RUN: 60\n",
    "VALIDATION ACCURACY = 76.36%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
